{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FCDUw0z5SEEP"
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import models\n",
    "import torchvision.utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#from torchattacks import PGD, FGSM, FFGSM\n",
    "import rep_transformations as rt\n",
    "from no_attack import NO_ATTACK\n",
    "from stochastic_attack import STOCHASTIC_ATTACK\n",
    "from fgsm_ import FGSM_\n",
    "from ffgsm_ import FFGSM_\n",
    "from slide_ import SLIDE_\n",
    "from pgd_ import PGD_\n",
    "from pgdl2_ import PGDL2_\n",
    "from data_transformations import DctBlurry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 11.1\n",
      "ID of current CUDA device: 0\n",
      "Name of current CUDA device: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "\n",
      "CUDA devide properties: _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060 Laptop GPU', major=8, minor=6, total_memory=6143MB, multi_processor_count=30)\n"
     ]
    }
   ],
   "source": [
    "#Show CUDA settings\n",
    "\n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "  \n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {cuda_id}\")\n",
    "\n",
    "cuda_name = torch.cuda.get_device_name(cuda_id)\n",
    "print(f\"Name of current CUDA device: {cuda_name}\\n\")\n",
    "print(f\"CUDA devide properties: {torch.cuda.get_device_properties(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vzPJjfl2StOo"
   },
   "outputs": [],
   "source": [
    "#Downloading Fashion MNIST Dataset\n",
    "train_list_transforms = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        #DctBlurry(threshold=5),\n",
    "    ])\n",
    "\n",
    "test_list_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "fashion_mnist_train = dsets.FashionMNIST(root='./data1/',\n",
    "                          train=True,\n",
    "                          transform=train_list_transforms,\n",
    "                          download=False)\n",
    "\n",
    "fashion_mnist_aux = dsets.FashionMNIST(root='./data1/',\n",
    "                         train=False,\n",
    "                         transform=test_list_transforms,\n",
    "                         download=False)\n",
    "\n",
    "fashion_mnist_test, fashion_mnist_valid = torch.utils.data.random_split(fashion_mnist_aux, [5000, 5000], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VLOMLHG7S2_7"
   },
   "outputs": [],
   "source": [
    "#Initialize DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "torch.manual_seed(0)\n",
    "n_workers = 5\n",
    "\n",
    "train_loader  = torch.utils.data.DataLoader(dataset=fashion_mnist_train,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=42, num_workers=n_workers)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=fashion_mnist_test,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=42, num_workers=n_workers)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=fashion_mnist_valid,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=42, num_workers=n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize transformations\n",
    "\n",
    "id_transf = rt.Identity()\n",
    "fft_transf = rt.FFT()\n",
    "dct_transf = rt.DCT()\n",
    "jpeg_transf = rt.JPEG()\n",
    "\n",
    "list_transf = [id_transf, fft_transf, dct_transf, jpeg_transf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HRAlJTAVTK7h"
   },
   "outputs": [],
   "source": [
    "#Get model and optimizer\n",
    "\n",
    "def generate_model(pretrained=True, lr=0.001):\n",
    "\n",
    "    #Init model and optimizer\n",
    "    model = torchvision.models.resnet50(pretrained=True).cuda() #CNN.cuda() to resnet 50\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    #Change model architecture \n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    model.fc = nn.Linear(2048, 10, bias=True)\n",
    "    \n",
    "    #Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        model.to(device)\n",
    "        \n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "u3Hfg6f-X363"
   },
   "outputs": [],
   "source": [
    "#modified test function with 3 attacks and toggle between Pixel and DCT representation.Default is Pixel\n",
    "\n",
    "def get_accuracy(model, test_loader, atk):\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0    \n",
    "\n",
    "    for images, labels in test_loader:\n",
    "\n",
    "        images = atk(images, labels).cuda()              \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "    return 100 * float(correct) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mRXfnbnCYSUU"
   },
   "outputs": [],
   "source": [
    "#train function with PGD attack and toggle between DCT and Pixel representation .Default is Pixel\n",
    "\n",
    "def train_(model, train_loader, optimizer, loss, atk, num_epochs=5):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        total_batch = len(fashion_mnist_train) // batch_size\n",
    "        \n",
    "        for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "\n",
    "           \n",
    "            Y = batch_labels.cuda()\n",
    "            X = atk(batch_images, batch_labels).cuda()\n",
    "\n",
    "            pre = model(X)\n",
    "            cost = loss(pre, Y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'Train. Atk: {atk.attack}, Epoch [{epoch+1}/{num_epochs}], lter [{i+1}/{total_batch}], Loss: {cost.item()}')\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ymJCu20wYWnx"
   },
   "outputs": [],
   "source": [
    "def round_robin(model, train_loader, optimizer, loss, atks_list, num_epochs=5):\n",
    "\n",
    "    model.train() \n",
    "    num_attacks = len(atks_list)\n",
    "    total_batch = len(fashion_mnist_train) // batch_size\n",
    "\n",
    "    for epoch in range(num_epochs): #+1 to round up\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "\n",
    "            atk = atks_list[count]\n",
    "            Y = batch_labels.cuda()\n",
    "            X = atk(batch_images, batch_labels).cuda()\n",
    "\n",
    "            pre = model(X)\n",
    "            cost = loss(pre, Y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            count += 1\n",
    "            count %= num_attacks\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'RR. Epoch [{epoch+1}/{num_epochs}], lter [{i+1}/{total_batch}], Loss: {cost.item()}')\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lPmwfoS0YZtv"
   },
   "outputs": [],
   "source": [
    "def greedy(model, train_loader, valid_loader, optimizer, loss, atks_list, num_epochs=5):\n",
    "\n",
    "    num_attacks = len(atks_list)\n",
    "    total_batch = len(fashion_mnist_train) // batch_size\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        loss_list = [0]*num_attacks\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for i, (batch_images, batch_labels) in enumerate(valid_loader):\n",
    "\n",
    "            Y = batch_labels.cuda()\n",
    "            current_batch_size = Y.shape[0]\n",
    "\n",
    "            for i, atk in enumerate(atks_list):\n",
    "\n",
    "                X = atk(batch_images, batch_labels).cuda()\n",
    "\n",
    "                pre = model(X)\n",
    "                cost = loss(pre, Y)\n",
    "\n",
    "                loss_list[i] += float(cost)/current_batch_size\n",
    "\n",
    "        max_loss_arg = np.argmax(np.array(loss_list))\n",
    "        atk = atks_list[max_loss_arg]\n",
    "\n",
    "        print(f\"Greedy. Epoch [{epoch+1}/{num_epochs}], Worst loss attack: {atk.attack}, loss: {loss_list[max_loss_arg]}\")\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "\n",
    "            Y = batch_labels.cuda()\n",
    "            X = atk(batch_images, batch_labels).cuda()\n",
    "\n",
    "            pre = model(X)\n",
    "            cost = loss(pre, Y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'Greedy. Epoch [{epoch+1}/{num_epochs}], lter [{i+1}/{total_batch}], Loss: {cost.item()}')\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9wi-G1x3YcNz"
   },
   "outputs": [],
   "source": [
    "def multivariate_probability(model, train_loader, valid_loader, optimizer, loss, atks_list, num_epochs=5):\n",
    "\n",
    "    num_attacks = len(atks_list)\n",
    "    total_batch = len(fashion_mnist_train) // batch_size\n",
    "    w_list = [1]*num_attacks\n",
    "    eta = 0.1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        loss_list = [0]*num_attacks\n",
    "        model.eval()\n",
    "\n",
    "        for i, (batch_images, batch_labels) in enumerate(valid_loader):\n",
    "\n",
    "            Y = batch_labels.cuda()\n",
    "            current_batch_size = Y.shape[0]\n",
    "\n",
    "            for i, atk in enumerate(atks_list):\n",
    "\n",
    "                X = atk(batch_images, batch_labels).cuda()\n",
    "\n",
    "                pre = model(X)\n",
    "                cost = loss(pre, Y)\n",
    "\n",
    "                loss_list[i] += float(cost)/current_batch_size\n",
    "\n",
    "        loss_list = np.array(loss_list)\n",
    "        total_loss = loss_list.sum()\n",
    "        prob_list = np.cumsum(loss_list)\n",
    "        prob_list /= total_loss\n",
    "\n",
    "        log = f\"MP. Epoch [{epoch+1}/{num_epochs}], atks: \"\n",
    "        for i, atk in enumerate(atks_list):\n",
    "            log += f\"({atk.attack},{prob_list[i]}) \"\n",
    "\n",
    "        print(log)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "\n",
    "            rand = random.random()\n",
    "            atk_idx = 0\n",
    "            for j in range(1,num_attacks):\n",
    "                if rand > prob_list[j]:\n",
    "                    atk_idx = j\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            atk = atks_list[atk_idx]\n",
    "            Y = batch_labels.cuda()\n",
    "            X = atk(batch_images, batch_labels).cuda()\n",
    "\n",
    "            pre = model(X)\n",
    "            cost = loss(pre, Y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'MP. Epoch [{epoch+1}/{num_epochs}], lter [{i+1}/{total_batch}], Loss: {cost.item()}')\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Nj-Ihk2qYjcZ"
   },
   "outputs": [],
   "source": [
    "def get_model_acc(model, test_loader, atks_list):\n",
    "    \n",
    "    model_acc = {}\n",
    "    \n",
    "    for atk in atks_list:\n",
    "        model_atk_acc = get_accuracy(model, test_loader, atk)\n",
    "        model_acc[atk.attack] = model_atk_acc\n",
    "        \n",
    "    return model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define attacks_list generation\n",
    "\n",
    "def generate_atks(model_atk, eps=0.3):\n",
    "    \n",
    "    atks_list = []\n",
    "    atks_list.append(NO_ATTACK(model_atk))\n",
    "    atks_list.append(STOCHASTIC_ATTACK(model_atk, eps=eps))\n",
    "    atks_list.append(FGSM_(model_atk, eps=eps))\n",
    "    atks_list.append(PGD_(model_atk, eps=eps))\n",
    "    atks_list.append(PGD_(model_atk, eps=eps, transf=dct_transf))\n",
    "    atks_list.append(PGD_(model_atk, eps=eps, transf=fft_transf))\n",
    "        \n",
    "    return atks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_avg(n_models=1, procedure=\"None\", num_epochs=5, eps=0.3):\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    iters_result = {}\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        model, optim = generate_model()\n",
    "        atks_model = generate_atks(model, eps=eps)\n",
    "        \n",
    "        if iters_result == {}:\n",
    "            for atk in atks_model:\n",
    "                iters_result[atk.attack] = []\n",
    "\n",
    "        cost0=train_(model,train_loader,optim,loss,atks_model[0], num_epochs=num_epochs)\n",
    "\n",
    "        if procedure == \"RR\":\n",
    "            cost1 = round_robin(model,train_loader,optim,loss,atks_model, num_epochs=num_epochs)\n",
    "        elif procedure == \"Greedy\":\n",
    "            cost1 = greedy(model,train_loader,valid_loader,optim,loss,atks_model, num_epochs=num_epochs)\n",
    "        elif procedure == \"MP\":\n",
    "            cost1 = multivariate_probability(model,train_loader,valid_loader,optim,loss,atks_model, num_epochs=num_epochs)\n",
    "        elif procedure == \"PGD\":\n",
    "            atk_pgd = PGD_(model, eps=eps, steps=20)\n",
    "            cost1 = train_(model,train_loader,optim,loss,atk_pgd, num_epochs=num_epochs)\n",
    "        elif procedure == \"PGD_DCT\":\n",
    "            atk_pgd_dct = PGD_(model, eps=eps, steps=20, transf=dct_transf)\n",
    "            cost1 = train_(model,train_loader,optim,loss,atk_pgd_dct, num_epochs=num_epochs)\n",
    "        elif procedure == \"PGD_FFT\":\n",
    "            atk_pgd_fft = PGD_(model, eps=eps, steps=20, transf=fft_transf)\n",
    "            cost1 = train_(model,train_loader,optim,loss,atk_pgd_fft, num_epochs=num_epochs)\n",
    "        \n",
    "        acc = get_model_acc(model, test_loader, atks_model)\n",
    "        \n",
    "        for (key, value) in acc.items():\n",
    "            temp = iters_result[key]\n",
    "            temp.append(value)\n",
    "            iters_result[key] = temp\n",
    "            \n",
    "        print(f'Model average. Iter: {i+1}/{n_models}.')\n",
    "            \n",
    "    results = {}\n",
    "    for (key, values) in iters_result.items():\n",
    "        aux_array = np.array(values)\n",
    "        mean = np.mean(aux_array)\n",
    "        std = np.std(aux_array)\n",
    "        results[key] = str(round(mean, 2))+\"+\"+str(round(std, 2))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Stop cell",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStop cell\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Stop cell"
     ]
    }
   ],
   "source": [
    "raise Exception('Stop cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [100/468], Loss: 0.513713002204895\n",
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [200/468], Loss: 0.3376750648021698\n",
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [300/468], Loss: 0.3800686299800873\n",
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [400/468], Loss: 0.3380638659000397\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [100/468], Loss: 0.2609924077987671\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [200/468], Loss: 0.31914377212524414\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [300/468], Loss: 0.4122563898563385\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [400/468], Loss: 0.2219519019126892\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [100/468], Loss: 0.31166574358940125\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [200/468], Loss: 0.38975754380226135\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [300/468], Loss: 0.29448363184928894\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [400/468], Loss: 0.2129490077495575\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [100/468], Loss: 0.22671553492546082\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [200/468], Loss: 0.21210798621177673\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [300/468], Loss: 0.22289413213729858\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [400/468], Loss: 0.36298877000808716\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [100/468], Loss: 0.2777422070503235\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [200/468], Loss: 0.2720339894294739\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [300/468], Loss: 0.22188740968704224\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [400/468], Loss: 0.244807630777359\n",
      "Model average. Iter: 1/1.\n"
     ]
    }
   ],
   "source": [
    "#Generate accuracy df/table\n",
    "std_acc = get_model_avg(n_models=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omen1\\AppData\\Local\\Temp\\ipykernel_6924\\326607975.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(std_acc, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO_ATTACK</th>\n",
       "      <th>RAND_ID</th>\n",
       "      <th>FGSM_ID</th>\n",
       "      <th>PGD_ID</th>\n",
       "      <th>PGD_DCT</th>\n",
       "      <th>PGD_FFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.94+0.0</td>\n",
       "      <td>58.22+0.0</td>\n",
       "      <td>4.06+0.0</td>\n",
       "      <td>0.0+0.0</td>\n",
       "      <td>0.0+0.0</td>\n",
       "      <td>3.56+0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NO_ATTACK    RAND_ID   FGSM_ID   PGD_ID  PGD_DCT   PGD_FFT\n",
       "0  89.94+0.0  58.22+0.0  4.06+0.0  0.0+0.0  0.0+0.0  3.56+0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = list(std_acc.keys()))\n",
    "df = df.append(std_acc, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [100/468], Loss: 0.4125092625617981\n",
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [200/468], Loss: 0.38737356662750244\n",
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [300/468], Loss: 0.4223770797252655\n",
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [400/468], Loss: 0.34672805666923523\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [100/468], Loss: 0.29110419750213623\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [200/468], Loss: 0.26789724826812744\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [300/468], Loss: 0.4032040536403656\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [400/468], Loss: 0.3963630497455597\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [100/468], Loss: 0.3231086730957031\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [200/468], Loss: 0.34578952193260193\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [300/468], Loss: 0.1838809698820114\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [400/468], Loss: 0.2844764292240143\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [100/468], Loss: 0.21861809492111206\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [200/468], Loss: 0.27886414527893066\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [300/468], Loss: 0.24638184905052185\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [400/468], Loss: 0.12815237045288086\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [100/468], Loss: 0.17214207351207733\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [200/468], Loss: 0.15934310853481293\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [300/468], Loss: 0.1642123907804489\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [400/468], Loss: 0.22847308218479156\n",
      "Train. Atk: PGD_ID, Epoch [1/5], lter [100/468], Loss: 1.5094857215881348\n",
      "Train. Atk: PGD_ID, Epoch [1/5], lter [200/468], Loss: 1.2041126489639282\n",
      "Train. Atk: PGD_ID, Epoch [1/5], lter [300/468], Loss: 1.2590255737304688\n",
      "Train. Atk: PGD_ID, Epoch [1/5], lter [400/468], Loss: 1.2276498079299927\n",
      "Train. Atk: PGD_ID, Epoch [2/5], lter [100/468], Loss: 1.1223244667053223\n",
      "Train. Atk: PGD_ID, Epoch [2/5], lter [200/468], Loss: 1.008171796798706\n",
      "Train. Atk: PGD_ID, Epoch [2/5], lter [300/468], Loss: 1.088769555091858\n",
      "Train. Atk: PGD_ID, Epoch [2/5], lter [400/468], Loss: 1.2043771743774414\n",
      "Train. Atk: PGD_ID, Epoch [3/5], lter [100/468], Loss: 1.2078238725662231\n",
      "Train. Atk: PGD_ID, Epoch [3/5], lter [200/468], Loss: 1.030716896057129\n",
      "Train. Atk: PGD_ID, Epoch [3/5], lter [300/468], Loss: 1.1533845663070679\n",
      "Train. Atk: PGD_ID, Epoch [3/5], lter [400/468], Loss: 1.1586906909942627\n",
      "Train. Atk: PGD_ID, Epoch [4/5], lter [100/468], Loss: 1.0397429466247559\n",
      "Train. Atk: PGD_ID, Epoch [4/5], lter [200/468], Loss: 1.0770796537399292\n",
      "Train. Atk: PGD_ID, Epoch [4/5], lter [300/468], Loss: 0.9629543423652649\n",
      "Train. Atk: PGD_ID, Epoch [4/5], lter [400/468], Loss: 1.147745966911316\n",
      "Train. Atk: PGD_ID, Epoch [5/5], lter [100/468], Loss: 1.1020876169204712\n",
      "Train. Atk: PGD_ID, Epoch [5/5], lter [200/468], Loss: 1.0611921548843384\n",
      "Train. Atk: PGD_ID, Epoch [5/5], lter [300/468], Loss: 0.8767279982566833\n",
      "Train. Atk: PGD_ID, Epoch [5/5], lter [400/468], Loss: 0.9195799827575684\n",
      "Model average. Iter: 1/1.\n"
     ]
    }
   ],
   "source": [
    "std_acc = get_model_avg(n_models=1, procedure='PGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omen1\\AppData\\Local\\Temp\\ipykernel_6924\\326607975.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(std_acc, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO_ATTACK</th>\n",
       "      <th>RAND_ID</th>\n",
       "      <th>FGSM_ID</th>\n",
       "      <th>PGD_ID</th>\n",
       "      <th>PGD_DCT</th>\n",
       "      <th>PGD_FFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.96+0.0</td>\n",
       "      <td>75.96+0.0</td>\n",
       "      <td>36.3+0.0</td>\n",
       "      <td>38.9+0.0</td>\n",
       "      <td>12.12+0.0</td>\n",
       "      <td>67.88+0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NO_ATTACK    RAND_ID   FGSM_ID    PGD_ID    PGD_DCT    PGD_FFT\n",
       "0  75.96+0.0  75.96+0.0  36.3+0.0  38.9+0.0  12.12+0.0  67.88+0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.append(std_acc, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [100/468], Loss: 0.5426807403564453\n",
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [200/468], Loss: 0.2903284430503845\n",
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [300/468], Loss: 0.3719025254249573\n",
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [400/468], Loss: 0.4022098183631897\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [100/468], Loss: 0.3333759903907776\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [200/468], Loss: 0.3562858998775482\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [300/468], Loss: 0.3949110209941864\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [400/468], Loss: 0.22702866792678833\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [100/468], Loss: 0.18499025702476501\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [200/468], Loss: 0.2900475561618805\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [300/468], Loss: 0.30780738592147827\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [400/468], Loss: 0.2132015973329544\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [100/468], Loss: 0.18636764585971832\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [200/468], Loss: 0.29403814673423767\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [300/468], Loss: 0.18638429045677185\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [400/468], Loss: 0.25758039951324463\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [100/468], Loss: 0.23601529002189636\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [200/468], Loss: 0.22207289934158325\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [300/468], Loss: 0.29600465297698975\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [400/468], Loss: 0.20774321258068085\n",
      "Train. Atk: PGD_DCT, Epoch [1/5], lter [100/468], Loss: 1.5391395092010498\n",
      "Train. Atk: PGD_DCT, Epoch [1/5], lter [200/468], Loss: 1.3444504737854004\n",
      "Train. Atk: PGD_DCT, Epoch [1/5], lter [300/468], Loss: 1.3758984804153442\n",
      "Train. Atk: PGD_DCT, Epoch [1/5], lter [400/468], Loss: 1.339154601097107\n",
      "Train. Atk: PGD_DCT, Epoch [2/5], lter [100/468], Loss: 1.4630671739578247\n",
      "Train. Atk: PGD_DCT, Epoch [2/5], lter [200/468], Loss: 1.292587399482727\n",
      "Train. Atk: PGD_DCT, Epoch [2/5], lter [300/468], Loss: 1.380417823791504\n",
      "Train. Atk: PGD_DCT, Epoch [2/5], lter [400/468], Loss: 1.2716377973556519\n",
      "Train. Atk: PGD_DCT, Epoch [3/5], lter [100/468], Loss: 1.335521936416626\n",
      "Train. Atk: PGD_DCT, Epoch [3/5], lter [200/468], Loss: 1.312863826751709\n",
      "Train. Atk: PGD_DCT, Epoch [3/5], lter [300/468], Loss: 1.3279893398284912\n",
      "Train. Atk: PGD_DCT, Epoch [3/5], lter [400/468], Loss: 1.1836066246032715\n",
      "Train. Atk: PGD_DCT, Epoch [4/5], lter [100/468], Loss: 1.2561239004135132\n",
      "Train. Atk: PGD_DCT, Epoch [4/5], lter [200/468], Loss: 1.2862749099731445\n",
      "Train. Atk: PGD_DCT, Epoch [4/5], lter [300/468], Loss: 1.3096519708633423\n",
      "Train. Atk: PGD_DCT, Epoch [4/5], lter [400/468], Loss: 1.3180925846099854\n",
      "Train. Atk: PGD_DCT, Epoch [5/5], lter [100/468], Loss: 1.3496520519256592\n",
      "Train. Atk: PGD_DCT, Epoch [5/5], lter [200/468], Loss: 1.1932216882705688\n",
      "Train. Atk: PGD_DCT, Epoch [5/5], lter [300/468], Loss: 1.1725560426712036\n",
      "Train. Atk: PGD_DCT, Epoch [5/5], lter [400/468], Loss: 1.272856593132019\n",
      "Model average. Iter: 1/1.\n"
     ]
    }
   ],
   "source": [
    "std_acc = get_model_avg(n_models=1, procedure='PGD_DCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omen1\\AppData\\Local\\Temp\\ipykernel_6924\\326607975.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(std_acc, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO_ATTACK</th>\n",
       "      <th>RAND_ID</th>\n",
       "      <th>FGSM_ID</th>\n",
       "      <th>PGD_ID</th>\n",
       "      <th>PGD_DCT</th>\n",
       "      <th>PGD_FFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.46+0.0</td>\n",
       "      <td>67.48+0.0</td>\n",
       "      <td>33.22+0.0</td>\n",
       "      <td>35.18+0.0</td>\n",
       "      <td>27.74+0.0</td>\n",
       "      <td>61.34+0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NO_ATTACK    RAND_ID    FGSM_ID     PGD_ID    PGD_DCT    PGD_FFT\n",
       "0  67.46+0.0  67.48+0.0  33.22+0.0  35.18+0.0  27.74+0.0  61.34+0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.append(std_acc, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [100/468], Loss: 0.5452799797058105\n",
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [200/468], Loss: 0.5244652032852173\n",
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [300/468], Loss: 0.4158513844013214\n",
      "Train. Atk: NO_ATTACK, Epoch [1/5], lter [400/468], Loss: 0.3192123472690582\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [100/468], Loss: 0.38677841424942017\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [200/468], Loss: 0.41045504808425903\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [300/468], Loss: 0.42866942286491394\n",
      "Train. Atk: NO_ATTACK, Epoch [2/5], lter [400/468], Loss: 0.5485684275627136\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [100/468], Loss: 0.29808947443962097\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [200/468], Loss: 0.29585617780685425\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [300/468], Loss: 0.20634204149246216\n",
      "Train. Atk: NO_ATTACK, Epoch [3/5], lter [400/468], Loss: 0.1856103241443634\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [100/468], Loss: 0.2325558066368103\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [200/468], Loss: 0.25433337688446045\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [300/468], Loss: 0.3605136573314667\n",
      "Train. Atk: NO_ATTACK, Epoch [4/5], lter [400/468], Loss: 0.3689197897911072\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [100/468], Loss: 0.1745256632566452\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [200/468], Loss: 0.19963237643241882\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [300/468], Loss: 0.31328293681144714\n",
      "Train. Atk: NO_ATTACK, Epoch [5/5], lter [400/468], Loss: 0.15886721014976501\n",
      "Train. Atk: PGD_FFT, Epoch [1/5], lter [100/468], Loss: 0.6773195266723633\n",
      "Train. Atk: PGD_FFT, Epoch [1/5], lter [200/468], Loss: 0.7147805690765381\n",
      "Train. Atk: PGD_FFT, Epoch [1/5], lter [300/468], Loss: 0.6855270266532898\n",
      "Train. Atk: PGD_FFT, Epoch [1/5], lter [400/468], Loss: 0.5092992782592773\n",
      "Train. Atk: PGD_FFT, Epoch [2/5], lter [100/468], Loss: 0.5599882006645203\n",
      "Train. Atk: PGD_FFT, Epoch [2/5], lter [200/468], Loss: 0.5231962203979492\n",
      "Train. Atk: PGD_FFT, Epoch [2/5], lter [300/468], Loss: 0.5268650650978088\n",
      "Train. Atk: PGD_FFT, Epoch [2/5], lter [400/468], Loss: 0.6688697934150696\n",
      "Train. Atk: PGD_FFT, Epoch [3/5], lter [100/468], Loss: 0.5056321620941162\n",
      "Train. Atk: PGD_FFT, Epoch [3/5], lter [200/468], Loss: 0.4753148853778839\n",
      "Train. Atk: PGD_FFT, Epoch [3/5], lter [300/468], Loss: 0.5302346348762512\n",
      "Train. Atk: PGD_FFT, Epoch [3/5], lter [400/468], Loss: 0.49246078729629517\n",
      "Train. Atk: PGD_FFT, Epoch [4/5], lter [100/468], Loss: 0.6066074371337891\n",
      "Train. Atk: PGD_FFT, Epoch [4/5], lter [200/468], Loss: 0.3613485097885132\n",
      "Train. Atk: PGD_FFT, Epoch [4/5], lter [300/468], Loss: 0.4344528913497925\n",
      "Train. Atk: PGD_FFT, Epoch [4/5], lter [400/468], Loss: 0.4270511567592621\n",
      "Train. Atk: PGD_FFT, Epoch [5/5], lter [100/468], Loss: 0.5259107947349548\n",
      "Train. Atk: PGD_FFT, Epoch [5/5], lter [200/468], Loss: 0.8261407613754272\n",
      "Train. Atk: PGD_FFT, Epoch [5/5], lter [300/468], Loss: 0.4934766888618469\n",
      "Train. Atk: PGD_FFT, Epoch [5/5], lter [400/468], Loss: 0.48303839564323425\n",
      "Model average. Iter: 1/1.\n"
     ]
    }
   ],
   "source": [
    "std_acc = get_model_avg(n_models=1, procedure='PGD_FFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omen1\\AppData\\Local\\Temp\\ipykernel_6924\\326607975.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(std_acc, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO_ATTACK</th>\n",
       "      <th>RAND_ID</th>\n",
       "      <th>FGSM_ID</th>\n",
       "      <th>PGD_ID</th>\n",
       "      <th>PGD_DCT</th>\n",
       "      <th>PGD_FFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.28+0.0</td>\n",
       "      <td>84.8+0.0</td>\n",
       "      <td>16.96+0.0</td>\n",
       "      <td>3.82+0.0</td>\n",
       "      <td>0.46+0.0</td>\n",
       "      <td>69.68+0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NO_ATTACK   RAND_ID    FGSM_ID    PGD_ID   PGD_DCT    PGD_FFT\n",
       "0  87.28+0.0  84.8+0.0  16.96+0.0  3.82+0.0  0.46+0.0  69.68+0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.append(std_acc, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate accuracy df/table\n",
    "std_acc = get_model_avg(n_models=5, procedure=\"RR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(std_acc, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QbnEh8cPYlJW",
    "outputId": "2b39be18-9243-48ee-aefe-59b9df23d5d0"
   },
   "outputs": [],
   "source": [
    "#Std accuracy\n",
    "cost0=train_(model,train_loader,optimizer,loss,atks_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = get_and_add_acc_model(model, test_loader, df_acc,atks_model, model_name=\"Std\")\n",
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "id": "bFtUIY1kYmSq",
    "outputId": "6a806de1-79dd-45ed-f186-f6d4d39c1d00"
   },
   "outputs": [],
   "source": [
    "# Round Robin accuracy\n",
    "cost_round0 = train_(model_round_rob,train_loader,optimizer_round_rob,loss,atks_model[0])\n",
    "cost_round1 = round_robin(model_round_rob,train_loader,optimizer_round_rob,loss,atks_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZfrNb8Nh9Ct"
   },
   "outputs": [],
   "source": [
    "df_acc = get_and_add_acc_model(model_round_rob, test_loader, df_acc, atks_model, model_name=\"RR\")\n",
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "_6TKqsbueWp6",
    "outputId": "e8a53dde-525c-4bd1-98b6-df51733a3d62"
   },
   "outputs": [],
   "source": [
    "# Greedy accuracy\n",
    "check_cuda_avaibilty() \n",
    "cost_greedy0 = train_(model_greedy,train_loader,optimizer_greedy,loss,atks_model[0])\n",
    "cost_greedy1 = greedy(model_greedy,train_loader,valid_loader,optimizer_greedy,loss,atks_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcpdXAg1ikCD"
   },
   "outputs": [],
   "source": [
    "df_acc = get_and_add_acc_model(model_greedy, test_loader, df_acc, atks_model, model_name=\"Greedy\")\n",
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWVLmrVrg6Rx"
   },
   "outputs": [],
   "source": [
    "#Multi prob. accuracy\n",
    "check_cuda_avaibilty() \n",
    "cost_mult_prob0 = train_(model_mult_prob,train_loader,optimizer_mult_prob,loss,atks_model[0])\n",
    "cost_mult_prob1 = multivariate_probability(model_mult_prob,train_loader,valid_loader,optimizer_mult_prob,loss,atks_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_MuXMatkdBD"
   },
   "outputs": [],
   "source": [
    "df_acc = get_and_add_acc_model(model_mult_prob, test_loader, df_acc, atks_model, model_name=\"MP\")\n",
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-S3Os7z-hAzn"
   },
   "outputs": [],
   "source": [
    "#Initial training in Pixel representation\n",
    "check_cuda_avaibilty() \n",
    "cost_rand0 = train_(model_rand, train_loader, optimizer_rand, loss, atks_model[0])\n",
    "cost_rand1 = train_(model_rand, train_loader, optimizer_rand, loss, atks_model[1], \"RANDOM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zQEAOiMhK0o"
   },
   "outputs": [],
   "source": [
    "df_acc = get_and_add_acc_model(model_rand, test_loader, df_acc, atks_model, \"Rand\")\n",
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkLTM7qfhLPf"
   },
   "outputs": [],
   "source": [
    "#Initial training in Pixel representation\n",
    "check_cuda_avaibilty() \n",
    "cost_pgd0 = train_(model_pgd, train_loader, optimizer_pgd, loss)\n",
    "cost_pgd1 = train_(model_pgd, train_loader, optimizer_pgd, loss, \"PGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGSMkeTdhMxS"
   },
   "outputs": [],
   "source": [
    "df_acc = get_and_add_acc_model(model_pgd, test_loader, df_acc, model_name=\"Pgd\")\n",
    "df_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsQoDwp-hOHw"
   },
   "outputs": [],
   "source": [
    "#Initial training in Pixel representation\n",
    "check_cuda_avaibilty() \n",
    "cost_pgd_dct0 = train_(model_pgd_dct, train_loader, optimizer_pgd_dct, loss)\n",
    "cost_pgd_dct1 = train_(model_pgd_dct, train_loader, optimizer_pgd_dct, loss, \"PGD_DCT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKNlKLlFhPtG"
   },
   "outputs": [],
   "source": [
    "df_acc = get_and_add_acc_model(model_pgd_dct, test_loader, df_acc, model_name=\"Pgd_dct\")\n",
    "df_acc"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
